{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e46e87f",
   "metadata": {},
   "source": [
    "# 5. Network in Network (NiN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9334b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eeeb06",
   "metadata": {},
   "source": [
    "LeNet, AlexNet, and VGG all share a common design pattern: **extract features exploiting spatial structure** via a sequence of convolutions and pooling layers and **post-process the representations** via fully connected layers. \n",
    "\n",
    "The **improvements** upon LeNet by AlexNet and VGG mainly lie in how these later networks **widen and deepen** these two modules.\n",
    "\n",
    "However, these networks poses 2 major **challenges**:\n",
    "\n",
    "1. the fully connected layers at the end consume **tremendous numbers of parameters**\n",
    "2. it is **impossible to add fully connected layers earlier** in the network to increase nonlinearity (doing so would destroy the spatial structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b5b867",
   "metadata": {},
   "source": [
    "## NiN Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b5b83e",
   "metadata": {},
   "source": [
    "The idea behind **`NiN`** is to apply a **fully connected layer** at each **pixel location**.\n",
    "\n",
    "NiN adopts independent **$1 \\times 1$ concolution layers** to act as fully connected layers (with ReLU activations) connecting the **pixels** at the **same location** across all the **channels**.\n",
    "\n",
    "A **NiN block** starts with a normal convolutional layers followed by two $1 \\times 1$ concolution layers. \n",
    "\n",
    "![](http://d2l.ai/_images/nin.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80efcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nin_block(in_channels, out_channels, kernel_size, strides, padding):\n",
    "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(out_channels, out_channels, kernel_size=1), \n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(out_channels, out_channels, kernel_size=1), \n",
    "                         nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a36ee",
   "metadata": {},
   "source": [
    "## NiN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab5496",
   "metadata": {},
   "source": [
    "The **NiN model** consists of **4 NiN blocks** with convolutional layers of shapes $11 \\times 11$, $5 \\times 5$ and $3 \\times 3$. \n",
    "\n",
    "The **number of channels** used is similar to that in the AlexNet. \n",
    "\n",
    "There is a $3 \\times 3$ **max-pooling** layer between each NiN block. \n",
    "\n",
    "Finally, the NiN model ends up with a **global average pooling** layer.\n",
    "\n",
    "Since there is no **fully connected layers** at the end of the model, the **number of output channels** is the number of classes and for each channel the **output** will have shape $1 \\times 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd5e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nin_block(in_channels=1, out_channels=96, kernel_size=11, strides=4, padding=0),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nin_block(in_channels=96, out_channels=256, kernel_size=5, strides=1, padding=2),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nin_block(in_channels=256, out_channels=384, kernel_size=3, strides=1, padding=1),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nin_block(in_channels=384, out_channels=10, kernel_size=3, strides=1, padding=1),\n",
    "                    nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "                    nn.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ceecb97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 96, 54, 54])\n",
      "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
      "Sequential output shape:\t torch.Size([1, 256, 26, 26])\n",
      "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 384, 12, 12])\n",
      "MaxPool2d output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Dropout output shape:\t torch.Size([1, 384, 5, 5])\n",
      "Sequential output shape:\t torch.Size([1, 10, 5, 5])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 10, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224, 224))\n",
    "\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
