{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03524b30",
   "metadata": {},
   "source": [
    "# 9. Densely Connected Networks (DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3ba297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87550365",
   "metadata": {},
   "source": [
    "## From ResNet to DenseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eee551",
   "metadata": {},
   "source": [
    "Similar to the **Taylor expansion**, we can decompose the desired mapping $f$ in ResNet:\n",
    "\n",
    "$f(x)=x+g(x)$\n",
    "\n",
    "into more than two terms. Such design can capture more information and is known as the **DenseNet**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57ff41",
   "metadata": {},
   "source": [
    "![](http://d2l.ai/_images/densenet-block.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457babed",
   "metadata": {},
   "source": [
    "As shown above, instead of **addition** as in ResNet, the outputs of a Dense Block are **concatenated**. \n",
    "\n",
    "As a result, we are actually performing a mapping from $x$ to its values after applying an **increasingly complex sequence** of functions:\n",
    "\n",
    "$$\\mathbf{x} \\to \\left[\n",
    "\\mathbf{x},\n",
    "f_1(\\mathbf{x}),\n",
    "f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right), f_3\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right), f_2\\left(\\left[\\mathbf{x}, f_1\\left(\\mathbf{x}\\right)\\right]\\right)\\right]\\right), \\ldots\\right]$$\n",
    "\n",
    "In the end, all these functions are combined using a **MLP layer** to reduce the number of features. The last layer of such a chain is **densely connected** to all the previous layers:\n",
    "\n",
    "![](http://d2l.ai/_images/densenet.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3afe8",
   "metadata": {},
   "source": [
    "## Dense Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda2b16",
   "metadata": {},
   "source": [
    "We first implement a **convolutional block**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0f4a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_channels, num_channels):\n",
    "    return nn.Sequential(nn.BatchNorm2d(input_channels), \n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1a467",
   "metadata": {},
   "source": [
    "A **dense block** consists of multiple convolutional blocks, each with the same number of **output channels**. \n",
    "\n",
    "In forward propagation, we **concatenate** the input and output of each convolution block on the channel dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c47936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_convs, input_channels, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(num_channels*i+input_channels, num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            X = torch.cat((X,Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9fe8e",
   "metadata": {},
   "source": [
    "In the following example, we define a DenseBlock instance with **2 convolution blocks** of **10 output channels**. \n",
    "\n",
    "When using an **input with 3 channels**, we will get an **output with $3+2\\times10=23$ channels**. The **number of convolution block channels** controls the growth in the number of output channels relative to the number of input channels. This is also referred to as the **growth rate**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a80761c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(num_convs=2, input_channels=3, num_channels=10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ca2b6",
   "metadata": {},
   "source": [
    "## Transition Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b61d7",
   "metadata": {},
   "source": [
    "Each dense block will increase the number of channels, which makes the model **more complex**. \n",
    "\n",
    "**Transition layers** are used to **reduce the number of channels** via $1\\times1$ convolutional layers and to **half the height and width of the output** via average-pooling layers with stride of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4bfe451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(input_channels, num_channels):\n",
    "    return nn.Sequential(nn.BatchNorm2d(input_channels), \n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "                         nn.AvgPool2d(kernel_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9174d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(23, 10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051ae1b",
   "metadata": {},
   "source": [
    "## DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "823b7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), \n",
    "                   nn.ReLU(),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a53d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels, growth_rate = 64, 32\n",
    "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
    "\n",
    "blks = []\n",
    "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
    "    \n",
    "    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
    "    num_channels += num_convs * growth_rate\n",
    "\n",
    "    if i != len(num_convs_in_dense_blocks) - 1:\n",
    "        blks.append(transition_block(num_channels, num_channels//2))\n",
    "        num_channels = num_channels//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d404b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(b1, *blks,\n",
    "                    nn.BatchNorm2d(num_channels), \n",
    "                    nn.ReLU(),\n",
    "                    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(num_channels, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
