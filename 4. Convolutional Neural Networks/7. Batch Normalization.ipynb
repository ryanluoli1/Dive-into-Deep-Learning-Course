{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e648e383",
   "metadata": {},
   "source": [
    "# 7. Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502aa052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f734f69",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c0e60",
   "metadata": {},
   "source": [
    "There are 3 main reason why **batch normalization** is essential:\n",
    "\n",
    "1. standardizes the scale of the input features\n",
    "2. big differences in scales might lead to training problems (e.g. learning rate must be adjusted)\n",
    "3. prevents deep neural networks from overfitting\n",
    "\n",
    "For an input $\\mathbf{x} \\in \\mathcal{B}$, **batch normalization** is defined as follows:\n",
    "\n",
    "$$\\mathrm{BN}(\\mathbf{x}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_\\mathcal{B}}{\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}} + \\boldsymbol{\\beta}$$\n",
    "\n",
    "where $\\hat{\\boldsymbol{\\mu}}_\\mathcal{B}$ and ${\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}}$ are the **mean** and **standard deviation** of the minibatch $\\mathcal{B}$:\n",
    "\n",
    "$$\\begin{aligned} \\hat{\\boldsymbol{\\mu}}_\\mathcal{B} &= \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} \\mathbf{x},\\\\\n",
    "\\hat{\\boldsymbol{\\sigma}}_\\mathcal{B}^2 &= \\frac{1}{|\\mathcal{B}|} \\sum_{\\mathbf{x} \\in \\mathcal{B}} (\\mathbf{x} - \\hat{\\boldsymbol{\\mu}}_{\\mathcal{B}})^2 + \\epsilon.\\end{aligned}$$\n",
    "\n",
    "and $\\boldsymbol{\\gamma}$ and $\\boldsymbol{\\beta}$ are the learnable parameters **scale** and **shift**.\n",
    "\n",
    "Note that batch normalization is based on the **statistics of the minibatch** in training but based on the **statistics on the entire dataset** when making predicitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81cdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "                    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "                    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "                    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "                    nn.Linear(84, 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
