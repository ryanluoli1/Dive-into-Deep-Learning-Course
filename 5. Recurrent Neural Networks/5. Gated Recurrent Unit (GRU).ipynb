{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e52740b",
   "metadata": {},
   "source": [
    "# 5. Gated Recurrent Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873fc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4734bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3ad610",
   "metadata": {},
   "source": [
    "We often avoid gradient exploding or vanishing in the cost of lossing some information in long sequences. The earliest solution is the **Long Short-term Memory** (LSTM). The **gated recurrent unit** (GRU) offered a **streamlined version** of the LSTM cell that often achieves comparable performance but with the advantage of being faster to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc41c6",
   "metadata": {},
   "source": [
    "## Reset Gate and Update Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091fffb",
   "metadata": {},
   "source": [
    "The biggest difference between GRU and RNN is that the former can control **when to reset and update** the hidden states using **gates**.\n",
    "\n",
    "The **reset gate** controls how much of the **previous state** we might still want to remember. The **update gate** would allow us to control how much of the **new state** is just a copy of the old state. \n",
    "\n",
    "In short:\n",
    "\n",
    "1. Reset gates help capture **short-term dependencies** in sequences.\n",
    "2. Update gates help capture **long-term dependencies** in sequences.\n",
    "\n",
    "The **outputs** of two gates are given by two **fully connected layers** with a **sigmoid** activation function that forces the values to in the interval (0,1).\n",
    "\n",
    "![](http://d2l.ai/_images/gru-1.svg)\n",
    "\n",
    "For a mini-batch input $\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$, the mathematical expression of the gates are given as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{R}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xr} + \\mathbf{H}_{t-1} \\mathbf{W}_{hr} + \\mathbf{b}_r)\\\\\n",
    "\\mathbf{Z}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xz} + \\mathbf{H}_{t-1} \\mathbf{W}_{hz} + \\mathbf{b}_z)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where we have $\\mathbf{R}_t \\in \\mathbb{R}^{n \\times h}$, $\\mathbf{Z}_t \\in \\mathbb{R}^{n \\times h}$, $\\mathbf{W}_{xr}, \\mathbf{W}_{xz} \\in \\mathbb{R}^{d \\times h}$, $\\mathbf{W}_{hr}, \\mathbf{W}_{hz} \\in \\mathbb{R}^{h \\times h}$, $\\mathbf{b}_r, \\mathbf{b}_z \\in \\mathbb{R}^{1 \\times h}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabb280",
   "metadata": {},
   "source": [
    "## Candidate Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a51fa",
   "metadata": {},
   "source": [
    "The **candidate hidden state** $\\tilde{\\mathbf{H}}_t \\in \\mathbb{R}^{n \\times h}$ at time step $t$ is obtained by integrating the **reset gate** with the **regular updating mechanism**:\n",
    "\n",
    "$$\\tilde{\\mathbf{H}}_t = \\tanh(\\mathbf{X}_t \\mathbf{W}_{xh} + \\left(\\mathbf{R}_t \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{hh} + \\mathbf{b}_h)$$\n",
    "\n",
    "where we have $\\mathbf{W}_{xh} \\in \\mathbb{R}^{d \\times h}$, $\\mathbf{W}_{hh} \\in \\mathbb{R}^{h \\times h}$, $\\mathbf{b}_h \\in \\mathbb{R}^{1 \\times h}$, and $\\odot$ is the Hadamard (elementwise) product operator.\n",
    "\n",
    "The **elementwise product** of $\\mathbf{R}_t$ and $\\mathbf{H}_{t-1}$ **reduces** the effect of the previous hidden states (i.e. controls how much **previous information** to remember):\n",
    "\n",
    "1. when the entries in the $\\mathbf{R}_t$ are close to 1, the GRU resembles a vanilla RNN (all previous information remembered)\n",
    "2. when the entries in the $\\mathbf{R}_t$ are close to 0, the candidate hidden state becomes the MLP output of $\\mathbf{X}_t$ (non of the previous information remembered)\n",
    "\n",
    "\n",
    "![](http://d2l.ai/_images/gru-2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de2ac9",
   "metadata": {},
   "source": [
    "## Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad84a13",
   "metadata": {},
   "source": [
    "The **update gate $\\mathbf{Z}_t$** determines the extent to which the **new hidden state $\\mathbf{H}_t \\in \\mathbb{R}^{n \\times h}$** matches the **old state $\\mathbf{H}_{t-1}$** versus how much it resembles the **new candidate hidden state $\\tilde{\\mathbf{H}}_t$**.\n",
    "\n",
    "This can be achieved by taking **elementwise convex combinations** of $\\mathbf{H}_{t-1}$ and $\\tilde{\\mathbf{H}}_t$ with $\\mathbf{Z}_t$:\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{Z}_t \\odot \\mathbf{H}_{t-1}  + (1 - \\mathbf{Z}_t) \\odot \\tilde{\\mathbf{H}}_t$$\n",
    "\n",
    "When $\\mathbf{Z}_t$ is close to 1, the model simply **retains** the old state. In this case, the information from $\\mathbf{X}_t$ is **ignored**, effectively **skipping time step $t$** in the dependency chain. \n",
    "\n",
    "In contrast, when $\\mathbf{Z}_t$ is close to 0, the new hidden state approaches the candidate hidden state.\n",
    "\n",
    "![](http://d2l.ai/_images/gru-3.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b154a",
   "metadata": {},
   "source": [
    "## Implementing GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c73b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed1546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14367f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_inputs = vocab_size\n",
    "num_epochs, lr = 500, 1\n",
    "\n",
    "gru_layer = nn.GRU(num_inputs, num_hiddens)\n",
    "\n",
    "model = d2l.RNNModel(gru_layer, len(vocab))\n",
    "model = model.to(device)\n",
    "\n",
    "d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
